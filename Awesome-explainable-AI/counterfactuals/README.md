# Counterfactual Explanation (Actionable Recourse)

Counterfactual explanations mainly target to find the mimimum perturbation which changes the original prediction(Ususlly from an undesirable prediction to ideal one). The perturbation itself is a valid instance following the real data distribution as the training samples. It has broad applications, E.g., finance, education, health care ect. Specifically, what should I do to get the credit card approved if I received the rejection. This task can be viewed as extracting knowledge/solutions from the black-box models. It belongs to the instance-level explanation. Quite interesting to dive deeper!!!

The two use cases of counterfactual explanations:

![counterfactual explanations](https://github.com/iversonicter/awesome-explainable-ai/blob/master/fig/cf.png)

## Survey papers 

[A Survey of Algorithmic Recourse: Contrastive Explanations and Consequential Recommendations](https://dl.acm.org/doi/pdf/10.1145/3527848), ACM Computing Survey 2022

[A Survey on the Robustness of Feature Importance and Counterfactual Explanations](https://arxiv.org/pdf/2111.00358.pdf), Arxiv 2022

[Can counterfactual explanations of AI systems’ predictions skew lay users’ causal intuitions about the world? If so, can we correct for that?](https://arxiv.org/pdf/2205.06241.pdf), Arxiv 2022

[Counterfactual explanations and how to find them:literature review and benchmarking](https://link.springer.com/article/10.1007/s10618-022-00831-6), DMKD 2022

[Benchmark Evaluation of Counterfactual Algorithms for XAI: From a White box to a Black box](https://arxiv.org/pdf/2203.02399.pdf), Arxiv preprint 2022

[Evaluating the Practicality of Counterfactual Explanations](https://ceur-ws.org/Vol-3277/paper3.pdf), XAI it 2022

[A Framework and Benchmarking Study for Counterfactual Generating Methods on Tabular Data](https://www.mdpi.com/2076-3417/11/16/7274), Applied Sciences 2021

[Counterfactual Explanations for Functional Data:A Mathematical Optimization Approach](https://www.researchgate.net/profile/Jasone-Ramirez-Ayerbe/publication/357700882_Counterfactual_Explanations_for_Functional_Data_A_Mathematical_Optimization_Approach/links/61dbed08e669ee0f5c997e79/Counterfactual-Explanations-for-Functional-Data-A-Mathematical-Optimization-Approach.pdf), Preprint 2021

[Counterfactuals and Causability in Explainable Artificial Intelligence: Theory, Algorithms, and Applications](https://arxiv.org/abs/2103.04244), Arxiv preprint 2021

[A Survey of Contrastive and Counterfactual Explanation Generation Methods for Explainable Artificial Intelligence](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9321372), IEEE Access 2021

[Good Counterfactuals and Where to Find Them: A Case-Based Technique for Generating Counterfactuals for Explainable AI (XAI)](https://arxiv.org/pdf/2005.13997.pdf), Arxiv preprint 2020

[Counterfactual Explanations for Machine Learning: A Review](https://arxiv.org/pdf/2010.10596.pdf), Arxiv preprint 2020

[A survey of algorithmic recourse: definitions, formulations, solutions, and prospects](https://arxiv.org/abs/2010.04050), Arxiv preprint 2020

[On the computation of counterfactual explanations -- A survey](https://arxiv.org/abs/1911.07749), Arxiv preprint 2019

[Issues with post-hoc counterfactual explanations: a discussion](https://arxiv.org/abs/1906.04774), ICML Workshop 2019

[Counterfactuals in Explainable Artificial Intelligence (XAI): Evidence from Human Reasoning](https://www.ijcai.org/Proceedings/2019/0876.pdf), IJCAI 2019

[CONTRASTIVE EXPLANATION: A STRUCTURAL-MODEL APPROACH](https://arxiv.org/pdf/1811.03163.pdf), Arxiv preprint 2018

## Papers

[Explaining Reinforcement Learning Agents through Counterfactual Action Outcomes](https://ojs.aaai.org/index.php/AAAI/article/view/28863/29640), AAAI 2024

[SafeAR: Safe Algorithmic Recourse by Risk-Aware Policies](https://arxiv.org/pdf/2308.12367), AAAI 2024

[Interpretable ECG Analysis for Myocardial Infarction Detection through Counterfactuals](https://arxiv.org/pdf/2312.08304.pdf), Arxiv 2023

[Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations](https://dl.acm.org/doi/abs/10.1145/3583780.3614885), CIKM 2023

[RoCourseNet: Robust Training of a Prediction Aware Recourse Model](https://dl.acm.org/doi/abs/10.1145/3583780.3615040), CIKM 2023

[Incentivizing Recourse through Auditing in Strategic Classifcation](https://www.ijcai.org/proceedings/2023/0045.pdf), IJCAI 2023

[Choose your Data Wisely: A Framework for Semantic Counterfactuals](https://www.ijcai.org/proceedings/2023/0043.pdf), IJCAI 2023

[Counterfactuals of Counterfactuals: a back-translation-inspired approach to analyse counterfactual editors](https://arxiv.org/abs/2305.17055), ACL Findings 2023

[DISCO: Distilling Counterfactuals with Large Language Models](https://arxiv.org/pdf/2212.10534.pdf), ACL 2023

[GAM Coach : Towards Interactive and User-centered Algorithmic Recourse](https://dl.acm.org/doi/fullHtml/10.1145/3544548.3580816), CHI 2023

[OCTET: Object-aware Counterfactual Explanations](https://arxiv.org/pdf/2211.12380.pdf), CVPR 2023

[Adversarial Counterfactual Visual Explanations](https://arxiv.org/abs/2303.09962), CVPR 2023

[Formalising the Robustness of Counterfactual Explanations for Neural Networks](https://arxiv.org/pdf/2208.14878.pdf), AAAI 2023

[Counterfactual Explanations for Concepts in ELH](https://arxiv.org/pdf/2301.05109.pdf), WWW 2023

[Beyond Known Reality: Exploiting Counterfactual Explanations for Medical Research](https://arxiv.org/pdf/2307.02131.pdf), Arxiv 2023

[CLEAR: Generative Counterfactual Explanations on Graphs](https://openreview.net/pdf?id=YR-s5leIvh), NeurIPS 2022

[Diffusion Visual Counterfactual Explanations](https://openreview.net/pdf?id=7SEi-ISNni7), NeurIPS 2022

[Counterfactual Explanations for Arbitrary Regression Models](https://arxiv.org/pdf/2106.15212.pdf), Arxiv 2022

[Evaluating Robustness of Counterfactual Explanations](https://arxiv.org/pdf/2103.02354.pdf), Arxiv 2022

[Let Users Decide: Navigating the Trade-offs Between Costs and Robustness in Algorithmic Recourse](https://arxiv.org/pdf/2203.06768.pdf), Arxiv 2022

[ReLAX: Reinforcement Learning Agent Explainer for Arbitrary Predictive Models](https://dl.acm.org/doi/abs/10.1145/3511808.3557429), CIKM 2022

[On the Adversarial Robustness of Causal Algorithmic Recourse](https://proceedings.mlr.press/v162/dominguez-olmedo22a/dominguez-olmedo22a.pdf), ICML 2022

[A query-optimal algorithm for finding counterfactuals](https://proceedings.mlr.press/v162/blanc22a/blanc22a.pdf), ICLM 2022

[Revisiting Contrastive Learning through the Lens of Neighborhood Component Analysis: an Integrated Framework](https://proceedings.mlr.press/v162/ko22a/ko22a.pdf), ICML 2022

[Robust Counterfactual Explanations for Tree-Based Ensembles](https://arxiv.org/abs/2207.02739), ICML 2022

[Why Am I Not Seeing It? Understanding Users’ Needs for
Counterfactual Explanations in Everyday Recommendations](https://facctconference.org/static/pdfs_2022/facct22-106.pdf), FAccT 2022

[Keep Your Friends Close and Your Counterfactuals Closer:
Improved Learning From Closest Rather Than Plausible
Counterfactual Explanations in an Abstract Setting](https://facctconference.org/static/pdfs_2022/facct22-164.pdf), FAccT 2022

[DualCF: Efficient Model Extraction Attack from Counterfactual Explanations](https://facctconference.org/static/pdfs_2022/facct22-105.pdf), FAccT 2022

[Counterfactual Shapley Additive Explanations](https://facctconference.org/static/pdfs_2022/facct22-87.pdf), FAccT 2022

[When adversarial attacks become interpretable Counterfactual explanations]([https://arxiv.org/pdf/2206.06854.pdf](https://hal.science/hal-03693355v1/file/hkr_explainability_Arxiv.pdf)), Arxiv 2022

[MACE: An Efficient Model-Agnostic Framework for Counterfactual Explanation](https://arxiv.org/abs/2205.15540), Arxiv 2022

[MotifExplainer: a Motif-based Graph Neural Network Explainer](https://arxiv.org/pdf/2202.00519.pdf), Arxiv 2022

[Diffusion Models for Counterfactual Explanations](https://arxiv.org/pdf/2203.15636.pdf), Arxiv 2022

[Counterfactual Explanations for Natural Language Interfaces](https://arxiv.org/pdf/2204.13192.pdf), ACL 2022

[Counterfactual Explanation Trees: Transparent and Consistent Actionable Recourse with Decision Trees](https://proceedings.mlr.press/v151/kanamori22a/kanamori22a.pdf), AISTATS 2022

[Consistent Counterfactuals for Deep Models](https://openreview.net/pdf?id=St6eyiTEHnG), ICLR 2022

[Counterfactual Models for Fair and Adequate Explanations](https://www.mdpi.com/2504-4990/4/2/14), MAKE 2022

[Cycle-Consistent Counterfactuals by Latent Transformations](https://arxiv.org/pdf/2203.15064.pdf), CVPR 2022

[STEEX: Steering Counterfactual Explanations with Semantics](https://arxiv.org/abs/2111.09094), ECCV 2022

[Framing Algorithmic Recourse for Anomaly Detection](https://arxiv.org/pdf/2206.14384.pdf), KDD 2022

[CF-GNNExplainer: Counterfactual Explanations for Graph Neural Networks](https://arxiv.org/abs/2102.03322), AISTATS 2022, [code](https://github.com/a-lucic/cf-gnnexplainer)

[Learning and Evaluating Graph Neural Network Explanations based on Counterfactual and Factual Reasoning](https://arxiv.org/pdf/2202.08816.pdf), WWW 2022

[On the Fairness of Causal Algorithmic Recourse](https://arxiv.org/pdf/2010.06529.pdf), AAAI 2022

[Unsupervised Editing for Counterfactual Stories](https://arxiv.org/pdf/2112.05417.pdf), AAAI 2022

CounterfactualGAN: [Generating Realistic Natural Language Counterfactuals](https://aclanthology.org/2021.findings-emnlp.306.pdf), EMNLP 2021

[Beyond Trivial Counterfactual Explanations with Diverse Valuable Explanations](https://openaccess.thecvf.com/content/ICCV2021/papers/Rodriguez_Beyond_Trivial_Counterfactual_Explanations_With_Diverse_Valuable_Explanations_ICCV_2021_paper.pdf), ICCV 2021

[Getting a CLUE: A Method for Explaining Uncertainty Estimates](https://arxiv.org/abs/2006.06848), ICLR 2021

[Counterfactual explanation of Bayesian model uncertainty](https://link.springer.com/article/10.1007/s00521-021-06528-z), Nerual Computing and Applications 2021

[Learning Models for Actionable Recourse](https://arxiv.org/abs/2011.06146), NeurIPS 2021

[Counterfactual Explanations in Sequential Decision Making Under Uncertainty](https://arxiv.org/abs/2107.02776), NeurIPS 2021

[Counterfactual Explanations Can Be Manipulated](https://arxiv.org/abs/2106.02666), NeurIPS 2021

[Towards Robust and Reliable Algorithmic Recourse](https://arxiv.org/pdf/2102.13620.pdf), NeurIPS 2021

[CARLA: A Python Library to Benchmark Algorithmic Recourse and Counterfactual Explanation Algorithms](https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/file/b53b3a3d6ab90ce0268229151c9bde11-Paper-round1.pdf), NeurIPS 2021

[The Skyline of Counterfactual Explanations for Machine Learning Decision Models](https://dl.acm.org/doi/abs/10.1145/3459637.3482397), CIKM 2021

[Counterfactual Explanations for Optimization-Based Decisions in the Context of the GDPR](https://www.ijcai.org/proceedings/2021/0564.pdf), IJCAI 2021

[Robust Counterfactual Explanations on Graph Neural Network](https://arxiv.org/pdf/2107.04086.pdf), NeurIPS 2021

[Explaining NLP Models via Minimal Contrastive Editing (MICE)](https://aclanthology.org/2021.findings-acl.336.pdf), ACL Findings 2021

[A Language for Counterfactual Generative Models](http://proceedings.mlr.press/v139/tavares21a/tavares21a.pdf), ICML 2021

[Optimal Counterfactual Explanations in Tree Ensembles](https://arxiv.org/abs/2106.06631), ICML 2021

[Model-Based Counterfactual Synthesizer for Interpretation](https://arxiv.org/pdf/2106.08971.pdf), KDD 2021

[Leveraging Latent Features for Local Explanations](https://arxiv.org/pdf/1905.12698.pdf), KDD 2021

[Counterfactual Graphs for Explainable Classification of Brain Networks](https://arxiv.org/abs/2106.08640), KDD 2021

[Polyjuice: Generating Counterfactuals for Explaining, Evaluating, and Improving Models](https://homes.cs.washington.edu/~wtshuang/static/papers/2021-acl-polyjuice.pdf), ACL 2021

[A Few Good Counterfactuals: Generating Interpretable, Plausible & Diverse Counterfactual Explanations](https://arxiv.org/pdf/2101.09056.pdf), Arxiv preprint 2021

[Model-agnostic and Scalable Counterfactual Explanations via Reinforcement Learning](https://arxiv.org/pdf/2106.02597.pdf), Arxiv preprint 2021

[GeCo: Quality Counterfactual Explanations in Real Time](https://arxiv.org/pdf/2101.01292.pdf), Arxiv preprint 2021

[Generating Interpretable Counterfactual Explanations By Implicit Minimisation of Epistemic and Aleatoric Uncertainties](https://arxiv.org/abs/2103.08951), AISTATS 2021, [code](https://github.com/oscarkey/explanations-by-minimizing-uncertainty)

[FIMAP: Feature Importance by Minimal Adversarial Perturbation](https://www.aaai.org/AAAI21Papers/AAAI-2721.Chapman-RoundsM.pdf), AAAI 2021

[Generate Your Counterfactuals: Towards Controlled Counterfactual Generation for Text](https://arxiv.org/pdf/2012.04698.pdf), AAAI 2021

[Counterfactual Fairness with Disentangled Causal Effect Variational Autoencoder](https://arxiv.org/pdf/2011.11878.pdf), AAAI 2021

[Counterfactual Explanations for Oblique Decision Trees: Exact, Efficient Algorithms](https://arxiv.org/abs/2103.01096), AAAI 2021

[Ordered Counterfactual Explanation by Mixed-Integer Linear Optimization](https://arxiv.org/abs/2012.11782), AAAI 2021

[Towards Unifying Feature Attribution and Counterfactual Explanations: Different Means to the Same End](https://arxiv.org/pdf/2011.04917.pdf), AIES 2021

[Interpretability Through Invertibility: A Deep Convolutional Network With Ideal Counterfactuals And Isosurfaces](https://openreview.net/forum?id=8YFhXYe1Ps)

[Counterfactual Generative Networks](http://www.cvlibs.net/publications/Sauer2021ICLR.pdf), ICLR 2021, [code](https://github.com/autonomousvision/counterfactual_generative_networks)

[Learning "What-if" Explanations for Sequential Decision-Making](https://openreview.net/forum?id=h0de3QWtGG), ICLR 2021

[GRACE: Generating Concise and Informative Contrastive Sample to Explain Neural Network Model’s Prediction](https://arxiv.org/abs/1911.02042), KDD 2020 [code](https://github.com/lethaiq/GRACE_KDD20)

[An ASP-Based Approach to Counterfactual Explanations for Classification](https://arxiv.org/pdf/2004.13237.pdf), RuleML + PR 2020

[DECE: Decision Explorer with Counterfactual Explanations for Machine Learning Models](https://arxiv.org/pdf/2008.08353.pdf), TVCG 2020

[Good Counterfactuals and Where to Find Them: A Case-Based Technique for Generating Counterfactuals for Explainable AI (XAI)](https://arxiv.org/pdf/2005.13997.pdf), ICCBR 2020

[Learning Global Transparent Models from Local Contrastive Explanations](https://arxiv.org/abs/2002.08247), NeurIPS 2020

[Decisions, Counterfactual Explanations and Strategic Behavior](https://arxiv.org/abs/2002.04333), NeurIPS 2020

[Algorithmic recourse under imperfect causal knowledge a probabilistic approach](https://arxiv.org/abs/2006.06831), NeurIPS 2020

[Beyond Individualized Recourse: Interpretable and Interactive Summaries of Actionable Recourses](https://arxiv.org/abs/2009.07165), NeurIPS 2020

[Generative causal explanations of black-box classifiers](https://papers.nips.cc/paper/2020/file/3a93a609b97ec0ab0ff5539eb79ef33a-Paper.pdf), NeurIPS 2020, [code](https://github.com/siplab-gt/generative-causal-explanations)

[Learning What Makes a Difference from Counterfactual Examples and Gradient Supervision](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123550579.pdf), ECCV 2020

[Counterfactual Vision-and-Language Navigation via Adversarial Path Sampler](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123510069.pdf), ECCV 2020

[Measurable Counterfactual Local Explanations for Any Classifier](http://ecai2020.eu/papers/514_paper.pdf), ECAI 2020

[CERTIFAI: Counterfactual Explanations for Robustness, Transparency, Interpretability, and Fairness of Artificial Intelligence models](https://arxiv.org/pdf/1905.07857.pdf),  AAAI/AIES 2020

[FACE: Feasible and Actionable Counterfactual Explanation](https://dl.acm.org/doi/abs/10.1145/3375627.3375850), AAAI/AIES 2020

[Counterfactual Explanations & Adversarial Examples](https://arxiv.org/pdf/2009.05487.pdf), Arxiv preprint 2020

[Instance-Based Counterfactual Explanations for Time Series Classification](https://arxiv.org/pdf/2009.13211.pdf), Arxiv preprint 2020

[On Relating 'Why?' and 'Why Not?' Explanations](https://arxiv.org/abs/2012.11067), Arxiv preprint 2020

[Model extraction from counterfactual explanations](https://arxiv.org/pdf/2009.01884.pdf), Arxiv preprint 2020

[Efficient computation of counterfactual explanations of LVQ models](https://arxiv.org/pdf/1908.00735.pdf), Arxiv preprint 2020

[Plausible Counterfactuals: Auditing Deep Learning Classifiers with Realistic Adversarial Examples](https://arxiv.org/pdf/2003.11323.pdf), Arxiv preprint 2020

[ViCE: Visual Counterfactual Explanations for Machine Learning Models](https://arxiv.org/pdf/2003.02428.pdf), IUI 2020

[Model extraction from counterfactual explanations](https://arxiv.org/pdf/2009.01884.pdf), Arxiv 2020

[Scaling Guarantees for Nearest Counterfactual Explanations](https://arxiv.org/abs/2010.04965), Arxiv preprint 2020

[PermuteAttack: Counterfactual Explanation of Machine Learning Credit Scorecards](https://arxiv.org/pdf/2008.10138.pdf), Arxiv preprint 2020

[Decisions, Counterfactual Explanations and Strategic Behavior](https://arxiv.org/abs/2002.04333), Arxiv preprint 2020

[FOCUS: Flexible Optimizable Counterfactual Explanations for Tree Ensembles](https://arxiv.org/abs/1911.12199), Arxiv preprint 2020

[Interpretable and Interactive Summaries of Actionable Recourses](https://arxiv.org/abs/2009.07165), Arxiv preprint 2020

[Counterfactual Explanation Based on Gradual Construction for Deep Networks](https://arxiv.org/abs/2008.01897), Arxiv preprint 2020

[CounteRGAN: Generating Realistic Counterfactuals with Residual Generative Adversarial Nets](https://arxiv.org/pdf/2009.05199.pdf), Arxiv preprint 2020

[EXPLAINABLE IMAGE CLASSIFICATION WITH EVIDENCE COUNTERFACTUAL](https://arxiv.org/pdf/2004.07511.pdf), Arxiv preprint 2020

[Model-Agnostic Counterfactual Explanations for Consequential Decisions](https://arxiv.org/abs/1905.11190), AISTATS 2020

[Explaining Data-Driven Decisions made by AI Systems: The Counterfactual Approach](https://arxiv.org/pdf/2001.07417.pdf), Arxiv preprint 2020

[On the Fairness of Causal Algorithmic Recourse](https://arxiv.org/pdf/2010.06529.pdf), Arxiv preprint 2020

[On Counterfactual Explanations under Predictive Multiplicity](http://proceedings.mlr.press/v124/pawelczyk20a.html), UAI 2020

[EXPLANATION BY PROGRESSIVE EXAGGERATION](https://iclr.cc/virtual_2020/poster_H1xFWgrFPS.html), ICLR 2020

[Learning the Difference that Makes a Difference with Counterfactually-augmented Data](https://openreview.net/attachment?id=Sklgs0NFvr&name=original_pdf), LCLR 2020

[Algorithmic Recourse: from Counterfactual Explanations to Interventions](https://arxiv.org/abs/2002.06278), Arxiv preprint 2020

[Learning Model-Agnostic Counterfactual Explanations for Tabular Data](https://dl.acm.org/doi/abs/10.1145/3366423.3380087),  ACM WWW 2020, [code](https://github.com/MartinPawel/c-chvae)

[The hidden assumptions behind counterfactual explanations and principal reasons](https://arxiv.org/pdf/1912.04930.pdf), ACM FAccT 2020

[Explaining Machine Learning Classifiers through Diverse Counterfactual Explanations](https://arxiv.org/pdf/1905.07697.pdf), ACM FAccT 2020

[The philosophical basis of algorithmic recourse](https://dl.acm.org/doi/abs/10.1145/3351095.3372876), ACM FAccT 2020

[Why Does My Model Fail? Contrastive Local Explanations for Retail Forecasting](https://arxiv.org/pdf/1908.00085.pdf), ACM FAccT 2020

[Convex Density Constraints for Computing Plausible Counterfactual Explanations](https://arxiv.org/pdf/2002.04862.pdf), ICANN 2020

[Fast Real-time Counterfactual Explanations](https://arxiv.org/pdf/2007.05684.pdf), ICML 2020 Workshop

[CRUDS: Counterfactual Recourse Using Disentangled Subspaces](https://finale.seas.harvard.edu/files/finale/files/cruds-_counterfactual_recourse_using_disentangled_subspaces.pdf), ICML 2020 Workshop

[DACE: Distribution-Aware Counterfactual Explanation by Mixed-Integer Linear Optimization](https://www.ijcai.org/Proceedings/2020/0395.pdf), IJCAI 2020

[Relation-Based Counterfactual Explanations for Bayesian Network Classifiers](https://www.ijcai.org/Proceedings/2020/63), IJCAI 2020

[PRINCE: Provider-side Interpretability with Counterfactual Explanations in Recommender Systems](https://arxiv.org/pdf/1911.08378.pdf), WSDM 2020

[CoCoX: Generating Conceptual and Counterfactual Explanations via Fault-Lines](https://aaai.org/ojs/index.php/AAAI/article/view/5643/5499), AAAI 2020

[SCOUT: Self-aware Discriminant Counterfactual Explanations](https://openaccess.thecvf.com/content_CVPR_2020/papers/Wang_SCOUT_Self-Aware_Discriminant_Counterfactual_Explanations_CVPR_2020_paper.pdf), CVPR 2020, [code](https://github.com/peiwang062/SCOUT)

[Multi-Objective Counterfactual Explanations](https://arxiv.org/pdf/2004.11165.pdf), PPSN 2020

[EMAP: Explanation by Minimal Adversarial Perturbation](https://arxiv.org/pdf/1912.00872.pdf), AAAI 2020

[Random forest explainability using counterfactual sets](https://doi.org/10.1016/j.inffus.2020.07.001), Information Fusion 2020

[The Dangers of Post-hoc Interpretability: Unjustified Counterfactual Explanations](https://www.ijcai.org/proceedings/2019/388), IJCAI 2019

[Multimodal Explanations by Predicting Counterfactuality in Videos](https://arxiv.org/pdf/1812.01263.pdf), CVPR 2019

[Unjustified Classification Regions and Counterfactual Explanations In Machine Learning](https://ecmlpkdd2019.org/downloads/paper/226.pdf), ECML-PDKK 2019

[Factual and Counterfactual Explanations for Black Box Decision Making](https://ieeexplore.ieee.org/document/8920138), IEEE Intelligent Systems 2019

[Model Agnostic Contrastive Explanations for Structured Data](https://arxiv.org/pdf/1906.00117.pdf), Arxiv preprint 2019

[Counterfactuals uncover the modular structure of deep generative models](https://arxiv.org/pdf/1812.03253.pdf), Arxiv preprint 2019

[Actionable Interpretability through Optimizable Counterfactual Explanations for Tree Ensembles](https://staff.fnwi.uva.nl/m.derijke/wp-content/papercite-data/pdf/lucic-2019-actionable-arxiv.pdf), arxiv preprint 2019

[Towards Realistic Individual Recourse and Actionable Explanations in Black-Box Decision Making Systems](https://arxiv.org/pdf/1907.09615.pdf), Arxiv preprint 2019

[Generative Counterfactual Introspection for Explainable Deep Learning](https://arxiv.org/abs/1907.03077), Arxiv preprint 2019

[Generating Counterfactual and Contrastive Explanations using SHAP](https://arxiv.org/pdf/1906.09293.pdf), Arxiv preprint 2019

[Interpretable Counterfactual Explanations Guided by Prototypes](https://arxiv.org/pdf/1907.02584.pdf), Arxiv preprint 2019

[Counterfactual Story Reasoning and Generation](http://aclanthology.lst.uni-saarland.de/D19-1509.pdf), EMNLP 2019

[Counterfactual Visual Explanations](https://arxiv.org/pdf/1904.07451.pdf), ICML 2019

[Counterfactual Explanation Algorithms for Behavioral and Textual Data](https://arxiv.org/abs/1912.01819), Arxiv preprint 2019

[Synthesizing Action Sequences for Modifying Model Decisions](https://arxiv.org/pdf/1910.00057.pdf), Arxiv preprint 2019

[Measurable Counterfactual Local Explanations for Any Classifier](https://arxiv.org/pdf/1908.03020.pdf), Arxiv preprint 2019

[Generating Contrastive Explanations with Monotonic Attribute Functions](https://arxiv.org/pdf/1905.12698.pdf), arxiv preprint 2019

[The What-If Tool: Interactive Probing of Machine Learning Models](https://arxiv.org/pdf/1907.04135v2.pdf), TVCG 2019

[Preserving Causal Constraints in Counterfactual Explanations for Machine Learning Classifiers](https://arxiv.org/abs/1912.03277), NeurIPS Workshop 2019

[Actionable Recourse in Linear Classification](https://dl.acm.org/doi/pdf/10.1145/3287560.3287566), ACM FAccT 2019

[EQUALIZING RECOURSE ACROSS GROUPS](https://arxiv.org/abs/1909.03166),  Arxiv preprint 2019

[Efficient Search for Diverse Coherent Explanations](https://arxiv.org/pdf/1901.04909.pdf), ACM FAccT 2019

[Counterfactual explanations of machine learning predictions: opportunities and challenges for AI safety](http://ceur-ws.org/Vol-2301/paper_20.pdf), SafeAI@AAAI 2019

[Explaining image classifiers by counterfactual generation](https://arxiv.org/pdf/1807.08024.pdf), ICLR 2019

[ExplainGAN: Model Explanation via Decision Boundary Crossing Transformations](https://openaccess.thecvf.com/content_ECCV_2018/papers/Nathan_Silberman_ExplainGAN_Model_Explanation_ECCV_2018_paper.pdf), ECCV 2018

[Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR](https://arxiv.org/abs/1711.00399), Hardvard Journal of Law & Technology 2018 (strong recommend)

[Contrastive Explanations with Local Foil Trees](https://arxiv.org/pdf/1806.07470.pdf), ICML Workshop on Human Interpretability in Machine Learning 2018

[Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives](https://papers.nips.cc/paper/7340-explanations-based-on-the-missing-towards-contrastive-explanations-with-pertinent-negatives), NIPS 2018, [code](https://github.com/IBM/Contrastive-Explanation-Method)

[Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections](https://arxiv.org/pdf/1802.07384.pdf), NIPS 2018

[Interpretable Credit Application Predictions With Counterfactual Explanations](https://arxiv.org/abs/1811.05245), Arxiv preprint 2018

[Comparison-based Inverse Classification for Interpretability in Machine Learning](https://hal.sorbonne-universite.fr/hal-01905982/document), IPMU 2018

[Generating Counterfactual Explanations with Natural Language](https://arxiv.org/pdf/1806.09809.pdf), ICML 2018 Workshop

[Grounding Visual Explanations](https://arxiv.org/pdf/1807.09685.pdf), ECCV 2018

[Interpreting Neural Network Judgments via Minimal, Stable, and Symbolic Corrections](https://proceedings.neurips.cc/paper/2018/file/300891a62162b960cf02ce3827bb363c-Paper.pdf), NeurIPS 2018

[Inverse Classification for Comparison-based Interpretability in Machine Learning](https://arxiv.org/pdf/1712.08443.pdf), Arxiv 2017

[Interpretable Predictions of Tree-based Ensembles via Actionable Feature Tweaking](https://arxiv.org/pdf/1706.06691.pdf), KDD 2017

[When Worlds Collide: Integrating Different Counterfactual Assumptions in Fairness](https://proceedings.neurips.cc/paper/2017/file/1271a7029c9df08643b631b02cf9e116-Paper.pdf), NeurIPS 2017

[A budget-constrained inverse classification framework for smooth classifiers](https://arxiv.org/abs/1605.09068), ICDMW 2017

[Generalized Inverse Classification](https://epubs.siam.org/doi/pdf/10.1137/1.9781611974973.19), SIAM 2017

[Explaining Data-Driven Document Classifications](http://pages.stern.nyu.edu/~fprovost/Papers/MartensProvost_Explaining.pdf), MIS Quarterly 2014

[The Inverse Classification Problem](https://link.springer.com/article/10.1007/s11390-010-9337-x), Journal of Computer Science and Technology 2010

[Assessing demand for intelli-gibility in context-aware applications](https://dl.acm.org/doi/10.1145/1620545.1620576), UbiComp '09

[The cost-minimizing inverse classification problem: a genetic algorithm approach](https://www.sciencedirect.com.remotexs.ntu.edu.sg/science/article/pii/S0167923600000774), Decision Support Systems 2000

[Counterfactuals](https://philpapers.org/rec/LEWC-2), Blackwell, Oxford 1973

## Github Repos

Alibi: [https://github.com/SeldonIO/alibi](https://github.com/SeldonIO/alibi) ![](https://img.shields.io/github/stars/SeldonIO/alibi.svg?style=social)

actionable-recourse: [https://github.com/ustunb/actionable-recourse](https://github.com/ustunb/actionable-recourse), Scikit-Learn ![](https://img.shields.io/github/stars/ustunb/actionable-recourse?style=social)

CEML: [https://github.com/andreArtelt/ceml](https://github.com/andreArtelt/ceml), Pytorch, Keras, Tensorflow, Scikit-Learn ![](https://img.shields.io/github/stars/andreArtelt/ceml?style=social)

Dice: [https://github.com/interpretml/DiCE.git](https://github.com/interpretml/DiCE.git), Pytorch, TensorFlow ![](https://img.shields.io/github/stars/interpretml/DiCE?style=social)

ContrastiveExplanation: [https://github.com/MarcelRobeer/ContrastiveExplanation](https://github.com/MarcelRobeer/ContrastiveExplanation), scikit-learn, ![](https://img.shields.io/github/stars/MarcelRobeer/ContrastiveExplanation?style=social)

cf-feasibility: [https://github.com/divyat09/cf-feasibility](https://github.com/divyat09/cf-feasibility), Pytorch, Tensorflow, Scikit-Learn, ![](https://img.shields.io/github/stars/divyat09/cf-feasibility?style=social)

Mace: [https://github.com/amirhk/mace](https://github.com/amirhk/mace), Scikit-Learn, ![](https://img.shields.io/github/stars/amirhk/mace?style=social)

Strategic-Decisions: [https://github.com/Networks-Learning/strategic-decisions](https://github.com/Networks-Learning/strategic-decisions), Scikit-learn ![](https://img.shields.io/github/stars/Networks-Learning/strategic-decisions?style=social)

Contrastive-Explanation-Method: [https://github.com/IBM/Contrastive-Explanation-Method](https://github.com/IBM/Contrastive-Explanation-Method), Tensorflow ![](https://img.shields.io/github/stars/IBM/Contrastive-Explanation-Method?style=social)
