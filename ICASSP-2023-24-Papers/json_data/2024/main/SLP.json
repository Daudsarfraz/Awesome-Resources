[
  {
    "title": "Diffusion-based Speech Enhancement in Matched and Mismatched Conditions using a Heun-based Sampler",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446610",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2312.02683",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement and Separation - Diffusion and other Probabilistic Models"
  },
  {
    "title": "Unsupervised Speech Enhancement with Diffusion-based Generative Models",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10447736",
    "github": "joanne-b-nortier/UDiffSE",
    "web_page": "https://team.inria.fr/multispeech/demos/udiffse/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2309.10450",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement and Separation - Diffusion and other Probabilistic Models"
  },
  {
    "title": "Boosting Speech Enhancement with Clean Self-Supervised Features via Conditional Variational Autoencoders",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10447220",
    "github": "YoonhyungLee94/SSFCVAE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement and Separation - Diffusion and other Probabilistic Models"
  },
  {
    "title": "Diffusion-based Speech Enhancement with a Weighted Generative-Supervised Learning Loss",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446805",
    "github": "jeaneudesAyilo/weighted_generative_supervised_DiffSE",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2309.10457",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement and Separation - Diffusion and other Probabilistic Models"
  },
  {
    "title": "AV2WAV: Diffusion-based Re-Synthesis from Continuous Self-Supervised Features for Audio-Visual Speech Enhancement",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446625",
    "github": null,
    "web_page": "https://home.ttic.edu/~jcchou/demo/avse/avse_demo.html",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2309.08030",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement and Separation - Diffusion and other Probabilistic Models"
  },
  {
    "title": "Seeing through the Conversation: Audio-Visual Speech Separation based on Diffusion Model",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10447679",
    "github": null,
    "web_page": "https://mm.kaist.ac.kr/projects/avdiffuss/",
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2310.19581",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement and Separation - Diffusion and other Probabilistic Models"
  }
]