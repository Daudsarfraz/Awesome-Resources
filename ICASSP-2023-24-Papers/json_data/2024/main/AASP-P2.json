[
  {
    "title": "Ultra Low Complexity Deep Learning based Noise Suppression",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10448353",
    "github": null,
    "web_page": null,
    "github_page": "https://fhgainr.github.io/ULCNet/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2312.08132",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement; Music Information Retrieval"
  },
  {
    "title": "A Closer Look at Wav2vec2 Embeddings for On-Device Single-Channel Speech Enhancement",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10447539",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2403.01369",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement; Music Information Retrieval"
  },
  {
    "title": "GTCRN: A Speech Enhancement Model Requiring Ultralow Computational Resources",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10448310",
    "github": "Xiaobin-Rong/gtcrn",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement; Music Information Retrieval"
  },
  {
    "title": "BAE-Net: A Low Complexity and High Fidelity Bandwidth-Adaptive Neural Network for Speech Super-Resolution",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446439",
    "github": "yuguochencuc/BAE-Net",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2312.13722",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement; Music Information Retrieval"
  },
  {
    "title": "DDD: A Perceptually Superior Low-Response-Time DNN-based Declipper",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10446235",
    "github": "stet-stet/DDD",
    "web_page": null,
    "github_page": "https://stet-stet.github.io/DDD/",
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2401.03650",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement; Music Information Retrieval"
  },
  {
    "title": "Enhancing Violin Fingering Generation through Audio-Symbolic Fusion",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10447910",
    "github": "wayonbvc/Violin-Fingering-Generation-Through-Audio-Symbolic-Fusion",
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement; Music Information Retrieval"
  },
  {
    "title": "Multi-View Midivae: Fusing Track- and Bar-View Representations for Long Multi-Track Symbolic Music Generation",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10448249",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": "2401.07532",
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement; Music Information Retrieval"
  },
  {
    "title": "A Scalable Sparse Transformer Model for Singing Melody Extraction",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10447953",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement; Music Information Retrieval"
  },
  {
    "title": "ByteHum: Fast and Accurate Query-by-Humming in the Wild",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10448117",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement; Music Information Retrieval"
  },
  {
    "title": "Joint Music and Language Attention Models for Zero-Shot Music Tagging",
    "base_url": null,
    "title_page": null,
    "ieee_id": "10447760",
    "github": null,
    "web_page": null,
    "github_page": null,
    "colab": null,
    "modelscope": null,
    "gitee": null,
    "gitlab": null,
    "zenodo": null,
    "kaggle": null,
    "demo_page": null,
    "paper_thecvf": null,
    "paper_arxiv_id": null,
    "paper_pdf": null,
    "paper_hal_science": null,
    "paper_researchgate": null,
    "paper_amazon": null,
    "youtube_id": null,
    "drive_google": null,
    "dropbox": null,
    "onedrive": null,
    "loom": null,
    "section": "Speech Enhancement; Music Information Retrieval"
  }
]