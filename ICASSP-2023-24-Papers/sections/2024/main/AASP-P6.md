# ICASSP-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICASSP-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/CI-L1.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/BISP-P7.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Audio and Speech Quality and Intelligibility Measures; Music Analysis

![Section Papers](https://img.shields.io/badge/Section%20Papers-12-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-9-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-4-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Non-Intrusive Speech Intelligibility Prediction for Hearing-Impaired Users Using Intermediate ASR Features and Human Memory Models | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447597-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447597) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.13611-b31b1b.svg)](https://arxiv.org/abs/2401.13611) | :heavy_minus_sign: |
| Corn: Co-Trained Full- and No-Reference Speech Quality Assessment | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447687-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447687) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2310.09388-b31b1b.svg)](https://arxiv.org/abs/2310.09388) | :heavy_minus_sign: |
| Multi-Task Pseudo-Label Learning for Non-Intrusive Speech Quality Assessment Model | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446712-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446712) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2308.09262-b31b1b.svg)](https://arxiv.org/abs/2308.09262) | :heavy_minus_sign: |
| Non-Intrusive Speech Quality Assessment with Multi-Task Learning Based on Tensor Network | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447695-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447695) | :heavy_minus_sign: |
| NOMAD: Unsupervised Learning of Perceptual Embeddings For Speech Enhancement and Non-Matching Reference Audio Quality Assessment | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448028-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448028) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2309.16284-b31b1b.svg)](https://arxiv.org/abs/2309.16284) | :heavy_minus_sign: |
| Speech Foundation Models on Intelligibility Prediction for Hearing-Impaired Listeners | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447907-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447907) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2401.14289-b31b1b.svg)](https://arxiv.org/abs/2401.14289) | :heavy_minus_sign: |
| MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://musicldm.github.io/) <br/> [![GitHub](https://img.shields.io/github/stars/RetroCirce/MusicLDM?style=flat)](https://github.com/RetroCirce/MusicLDM/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447265-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447265) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2308.01546-b31b1b.svg)](https://arxiv.org/abs/2308.01546) | :heavy_minus_sign: |
| A Comparative Analysis of Poetry Reading Audio: Singing, Narrating, or Somewhere In Between? | [![GitHub](https://img.shields.io/github/stars/kc82/poetry-reading?style=flat)](https://github.com/kc82/poetry-reading) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447582-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447582) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2404.00789-b31b1b.svg)](https://arxiv.org/abs/2404.00789) | :heavy_minus_sign: |
| MIR-MLPop: A Multilingual Pop Music Dataset with Time-Aligned Lyrics and Audio | [![GitHub](https://img.shields.io/github/stars/york135/MIRMLPop?style=flat)](https://github.com/york135/MIRMLPop) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447561-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447561) | :heavy_minus_sign: |
| Generating Stereophonic Music with Single-Stage Language Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://stereomusic-sslm.github.io/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446643-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446643) | :heavy_minus_sign: |
| String Sound Synthesizer on GPU-accelerated Finite Difference Scheme | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://cosmic-pillow-86e.notion.site/String-Sound-Synthesize-on-GPU-Accelerated-Finite-Difference-Scheme-8b8f3c98904044a08ccddc0782759f86) <br/> [![GitHub](https://img.shields.io/github/stars/jin-woo-lee/torch-fdtd-string?style=flat)](https://github.com/jin-woo-lee/torch-fdtd-string) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448242-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448242) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2311.18505-b31b1b.svg)](https://arxiv.org/abs/2311.18505) | :heavy_minus_sign: |
| Music Understanding LLaMA: Advancing Text-to-Music Generation with Question Answering and Captioning | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447027-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447027) <br/> [![arXiv](https://img.shields.io/badge/arXiv-2308.11276-b31b1b.svg)](https://arxiv.org/abs/2308.11276) | :heavy_minus_sign: |
