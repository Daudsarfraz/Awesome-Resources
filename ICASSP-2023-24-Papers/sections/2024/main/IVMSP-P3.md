# ICASSP-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICASSP-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/SLP-L14.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/IVMSP-P4.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Deep Learning for Image and Video Processing

![Section Papers](https://img.shields.io/badge/Section%20Papers-23-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-5-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-5-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| CLIP-Font: Sementic Self-Supervised Few-Shot Font Generation with Clip | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447490-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447490) | :heavy_minus_sign: |
| Gradient and Brightness Guided Low-Light Enhancement with Attention-based Self-Paced Learning | [![GitHub](https://img.shields.io/github/stars/MSL502/GBASPL?style=flat)](https://github.com/MSL502/GBASPL) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448307-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448307) | :heavy_minus_sign: |
| Implicit Neural Representation for Low-Overhead Graph-based Holographic-Type Communications | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445857-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445857) | :heavy_minus_sign: |
| Low-Light Raw Image Enhancement on a Dataset Suffering Light Effects | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447333-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447333) | :heavy_minus_sign: |
| DONE: Dynamic Neural Representation via Hyperplane Neural ODE | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446247-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446247) | :heavy_minus_sign: |
| A 3D Virtual Try-On Method with Global-Local Alignment and Diffusion Model | [![GitHub](https://img.shields.io/github/stars/Breaveh/VTON-GD?style=flat)](https://github.com/Breaveh/VTON-GD) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447311-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447311) | :heavy_minus_sign: |
| Lightweight High-Resolution Subject Matting in the Real World | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446680-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446680) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.07100-b31b1b.svg)](https://arxiv.org/abs/2312.07100) | :heavy_minus_sign: |
| Building Lane-Level Maps from Aerial Images | [![GitHub](https://img.shields.io/github/stars/Jiawei-Yao0812/AerialLaneNet?style=flat)](https://github.com/Jiawei-Yao0812/AerialLaneNet) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447410-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447410) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.13449-b31b1b.svg)](https://arxiv.org/abs/2312.13449) | :heavy_minus_sign: |
| HENet: Hyperbolic-based Encoder-Decoder Network for Word Spotting in Historical Mongolian Documents | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446514-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446514) | :heavy_minus_sign: |
| Complementary Fusion Network based on Frequency Hybrid Attention for Pansharpening | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446416-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446416) | :heavy_minus_sign: |
| RGB Images Enhancing Hyperspectral Image Denoising with Diffusion Model | [![GitHub](https://img.shields.io/github/stars/Dmsw/RGB-IMAGES-ENHANCING-HYPERSPECTRAL-IMAGE-DENOISING-WITH-DIFFUSION-MODEL?style=flat)](https://github.com/Dmsw/RGB-IMAGES-ENHANCING-HYPERSPECTRAL-IMAGE-DENOISING-WITH-DIFFUSION-MODEL) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448364-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448364) | :heavy_minus_sign: |
| Generalizable Two-Branch Framework for Image Class-Incremental Learning | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447078-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447078) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2402.18086-b31b1b.svg)](https://arxiv.org/abs/2402.18086) | :heavy_minus_sign: |
| Multiscale Attention Distillation for Object Detection | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447943-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447943) | :heavy_minus_sign: |
| MAS-NET: Mixed-Feature Attention Siamese Network for Change Detection on Remote Sensing Images | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446328-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446328) | :heavy_minus_sign: |
| Corner Detection based on a Rotation-Invariant and Noise-Insensitive Curvature Measurement | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445964-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445964) | :heavy_minus_sign: |
| Multi-Object Tracking for Unmanned Aerial Vehicles based on Multi-Frame Feature Fusion | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447050-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447050) | :heavy_minus_sign: |
| Gradually Spatio-Temporal Feature Activation for Target Tracking | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447555-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447555) | :heavy_minus_sign: |
| Deep Residual W-Unit Learning with Semantic Embedding for Automatic Pulmonary CT Artery-Vein Separation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448498-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448498) | :heavy_minus_sign: |
| Dynamic Clustering and Cluster Contrastive Learning for Unsupervised Person Re-Id with Feature Distribution Alignment | [![GitHub](https://img.shields.io/github/stars/theziqi/DCCC?style=flat)](https://github.com/theziqi/DCCC) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447711-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447711) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.06810-b31b1b.svg)](https://arxiv.org/abs/2303.06810) | :heavy_minus_sign: |
| Local Optimization Networks for Multi-View Multi-Person Human Posture Estimation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445922-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445922) | :heavy_minus_sign: |
| Facial Aesthetic Enhancement Network for Asian Faces based on Differential Facial Aesthetic Activations | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447427-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447427) | :heavy_minus_sign: |
| AttentionLUT: Attention Fusion-based Canonical Polyadic LUT for Real-Time Image Enhancement | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445905-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445905) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.01569-b31b1b.svg)](https://arxiv.org/abs/2401.01569) | :heavy_minus_sign: |
| Semantic-Guided Network with Contrastive Learning for Video Caption | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447433-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447433) | :heavy_minus_sign: |
