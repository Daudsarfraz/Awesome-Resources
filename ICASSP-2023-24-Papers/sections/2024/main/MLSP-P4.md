# ICASSP-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICASSP-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/BISP-P3.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/IFS-P1.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Learning from Multimodal Data

![Section Papers](https://img.shields.io/badge/Section%20Papers-29-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-8-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-9-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Synchformer: Efficient Synchronization from Sparse Cues | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.robots.ox.ac.uk/~vgg/research/synchformer/) <br /> [![GitHub](https://img.shields.io/github/stars/v-iashin/Synchformer?style=flat)](https://github.com/v-iashin/Synchformer) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448489-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448489) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.16423-b31b1b.svg)](https://arxiv.org/abs/2401.16423) | :heavy_minus_sign: |
| Joint Classification of Hyperspectral and Lidar Data using Cross-Modal Hierarchical Frequency Fusion Network | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446007-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446007) | :heavy_minus_sign: |
| Modality Re-Balance for Visual Question Answering: A Causal Framework | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447690-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447690) | :heavy_minus_sign: |
| A Fine-Grained Tri-Modal Interaction Model for Multimodal Sentiment Analysis | [![GitHub](https://img.shields.io/github/stars/zhixingyu/FGTI-MSA?style=flat)](https://github.com/zhixingyu/FGTI-MSA) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447872-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447872) | :heavy_minus_sign: |
| Enhancing Audio-Visual Question Answering with Missing Modality via Trans-Modal Associative Learning | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446292-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446292) | :heavy_minus_sign: |
| Multimodal Transformer with a Low-Computational-Cost Guarantee | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447954-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447954) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2402.15096-b31b1b.svg)](https://arxiv.org/abs/2402.15096) | :heavy_minus_sign: |
| Vision-Sensor Attention based Continual Multimodal Egocentric Activity Recognition | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446924-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446924) | :heavy_minus_sign: |
| Multi-View Subspace Clustering with Consensus Graph Contrastive Learning | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446405-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446405) | :heavy_minus_sign: |
| OLKAVS: An Open Large-Scale Korean Audio-Visual Speech Dataset | [![GitHub](https://img.shields.io/github/stars/IIP-Sogang/olkavs-avspeech?style=flat)](https://github.com/IIP-Sogang/olkavs-avspeech) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446901-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446901) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2301.06375-b31b1b.svg)](https://arxiv.org/abs/2301.06375) | :heavy_minus_sign: |
| Multi-Level Contrastive Learning for Hybrid Cross-Modal Retrieval | [![GitHub](https://img.shields.io/github/stars/JWargrave/MLCL?style=flat)](https://github.com/JWargrave/MLCL) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447444-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447444) | :heavy_minus_sign: |
| Rademacher Complexity Regularization for Correlation-based Multiview Representation Learning | [![GitHub](https://img.shields.io/github/stars/SSTGroup/RademacherRegCorrelationMRL?style=flat)](https://github.com/SSTGroup/RademacherRegCorrelationMRL) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446173-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446173) | :heavy_minus_sign: |
| NAC: Mitigating Noisy Correspondence in Cross-Modal Matching via Neighbor Auxiliary Corrector | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448059-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448059) | :heavy_minus_sign: |
| Image Retrieval with Composed Query by Multi-Scale Multi-Modal Fusion | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446291-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446291) | :heavy_minus_sign: |
| Beyond Empirical Windowing: An Attention-based Approach for Trust Prediction in Autonomous Vehicles | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446116-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446116) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.10209-b31b1b.svg)](https://arxiv.org/abs/2312.10209) | :heavy_minus_sign: |
| AV-SUPERB: A Multi-Task Evaluation Benchmark for Audio-Visual Representation Models | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://av.superbbenchmark.org/) <br /> [![GitHub](https://img.shields.io/github/stars/roger-tseng/av-superb?style=flat)](https://github.com/roger-tseng/av-superb) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445941-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445941) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.10787-b31b1b.svg)](https://arxiv.org/abs/2309.10787) | :heavy_minus_sign: |
| Incomplete Multi-View Representation Learning through Anchor Graph-based GCN and Information Bottleneck | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446535-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446535) | :heavy_minus_sign: |
| Language-guided Few-Shot Semantic Segmentation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447456-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447456) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.13865-b31b1b.svg)](https://arxiv.org/abs/2311.13865) | :heavy_minus_sign: |
| SweepMM: A High-Quality Multimodal Dataset for Sweeping Robots in Home Scenarios for Vision-Language Model | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447940-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447940) | :heavy_minus_sign: |
| Higher Order Multiple Graph Filtering for Structured Graph Learning | [![GitHub](https://img.shields.io/github/stars/lxd1204/HMGC?style=flat)](https://github.com/lxd1204/HMGC) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446826-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446826) | :heavy_minus_sign: |
| Multi-Grained Multimodal Interaction Network for Sentiment Analysis | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446351-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446351) | :heavy_minus_sign: |
| Multimodal Transformer Distillation for Audio-Visual Synchronization | [![GitHub](https://img.shields.io/github/stars/xjchenGit/MTDVocaLiST?style=flat)](https://github.com/xjchenGit/MTDVocaLiST) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446372-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446372) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2210.15563-b31b1b.svg)](https://arxiv.org/abs/2210.15563) | :heavy_minus_sign: |
| One-Step Late Fusion Multi-View Clustering with Compressed Subspace | [![GitHub](https://img.shields.io/github/stars/QiyuanOu/AblationStudy?style=flat)](https://github.com/QiyuanOu/AblationStudy) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447646-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447646) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.01558-b31b1b.svg)](https://arxiv.org/abs/2401.01558) | :heavy_minus_sign: |
| Self-Motion as Supervisionfor Egocentric Audiovisual Localization | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447683-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447683) | :heavy_minus_sign: |
| Adaptive Image-Enhanced Knowledge Graph Completion | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447212-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447212) | :heavy_minus_sign: |
| Dual-Mix for Cross-Modal Retrieval with Noisy Labels | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446808-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446808) | :heavy_minus_sign: |
| Fusing Multi-Level Features from Audio and Contextual Sentence Embedding from Text for Interview-based Depression Detection | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446253-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446253) | :heavy_minus_sign: |
| Synonym Replacement and Generation Enhancement for Document Augmentation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448339-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448339) | :heavy_minus_sign: |
| MACCN: Multi-Modal Adaptive Co-Attention Fusion Contrastive Learning Networks for Fake News Detection | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447435-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447435) | :heavy_minus_sign: |
| Visual-Linguistic Representation Learning with Deep Cross-Modality Fusion for Referring Multi-Object Tracking | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447535-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447535) | :heavy_minus_sign: |
