# ICASSP-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICASSP-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/MLSP-L4.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/AASP-L2.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Context and LLM Speech Recognition

![Section Papers](https://img.shields.io/badge/Section%20Papers-6-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-6-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-2-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Connecting Speech Encoder and Large Language Model for ASR | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445874-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445874) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.13963-b31b1b.svg)](https://arxiv.org/abs/2309.13963) | :heavy_minus_sign: |
| Adapting Large Language Model with Speech for Fully Formatted End-to-End Speech Recognition | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448204-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448204) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.08234-b31b1b.svg)](https://arxiv.org/abs/2307.08234) | :heavy_minus_sign: |
| PromptASR for Contextualized ASR with Controllable Style | [![GitHub](https://img.shields.io/github/stars/k2-fsa/icefall?style=flat)](https://github.com/k2-fsa/icefall) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448264-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448264) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.07414-b31b1b.svg)](https://arxiv.org/abs/2309.07414) | :heavy_minus_sign: |
| Extending Whisper with Prompt Tuning to Target-Speaker ASR | [![GitHub](https://img.shields.io/github/stars/Aisaka0v0/TS-Whisper?style=flat)](https://github.com/Aisaka0v0/TS-Whisper) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447492-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447492) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.08079-b31b1b.svg)](https://arxiv.org/abs/2312.08079) | :heavy_minus_sign: |
| Semi-Autoregressive Streaming ASR with Label Context | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446807-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446807) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.10926-b31b1b.svg)](https://arxiv.org/abs/2309.10926) | :heavy_minus_sign: |
| End-to-End Speech Recognition Contextualization with Large Language Models | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446898-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446898) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.10917-b31b1b.svg)](https://arxiv.org/abs/2309.10917) | :heavy_minus_sign: |
