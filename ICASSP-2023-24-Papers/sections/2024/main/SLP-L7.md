# ICASSP-2024-Papers

<table>
    <tr>
        <td><strong>Application</strong></td>
        <td>
            <a href="https://huggingface.co/spaces/DmitryRyumin/NewEraAI-Papers" style="float:left;">
                <img src="https://img.shields.io/badge/ðŸ¤—-NewEraAI--Papers-FFD21F.svg" alt="App" />
            </a>
        </td>
    </tr>
    <tr>
        <td><strong>Previous Collections</strong></td>
        <td>
            <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/README_2023.md">
                <img src="http://img.shields.io/badge/ICASSP-2023-0073AE.svg" alt="Conference">
            </a>
        </td>
    </tr>
</table>

<div align="center">
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/BISP-P5.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/left.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/home.svg" width="40" alt="" />
    </a>
    <a href="https://github.com/DmitryRyumin/ICASSP-2023-24-Papers/blob/main/sections/2024/main/AASP-L4.md">
        <img src="https://cdn.jsdelivr.net/gh/DmitryRyumin/NewEraAI-Papers@main/images/right.svg" width="40" alt="" />
    </a>
</div>

## Text to Speech Generation

![Section Papers](https://img.shields.io/badge/Section%20Papers-44-42BA16) ![Preprint Papers](https://img.shields.io/badge/Preprint%20Papers-34-b31b1b) ![Papers with Open Code](https://img.shields.io/badge/Papers%20with%20Open%20Code-11-1D7FBF) ![Papers with Video](https://img.shields.io/badge/Papers%20with%20Video-0-FF0000)

| **Title** | **Repo** | **Paper** | **Video** |
|-----------|:--------:|:---------:|:---------:|
| Creating Personalized Synthetic Voices from Articulation Impaired Speech using Augmented Reconstruction Loss | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://myspeechproject.github.io/ArticulationRepair/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446886-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446886) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.03816-b31b1b.svg)](https://arxiv.org/abs/2401.03816) | :heavy_minus_sign: |
| VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://cantabile-kwok.github.io/VoiceFlow/) <br /> [![GitHub](https://img.shields.io/github/stars/X-LANCE/VoiceFlow-TTS?style=flat)](https://github.com/X-LANCE/VoiceFlow-TTS) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445948-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445948) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.05027-b31b1b.svg)](https://arxiv.org/abs/2309.05027) | :heavy_minus_sign: |
| Matcha-TTS: A Fast TTS Architecture with Conditional Flow Matching | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://shivammehta25.github.io/Matcha-TTS/) <br /> [![GitHub](https://img.shields.io/github/stars/shivammehta25/Matcha-TTS?style=flat)](https://github.com/shivammehta25/Matcha-TTS) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448291-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448291) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.03199-b31b1b.svg)](https://arxiv.org/abs/2309.03199) | :heavy_minus_sign: |
| Extending Multilingual Speech Synthesis to 100+ Languages without Transcribed Data | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://google.github.io/tacotron/publications/extending_tts/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448074-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448074) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2402.18932-b31b1b.svg)](https://arxiv.org/abs/2402.18932) | :heavy_minus_sign: |
| PromptTTS++: Controlling Speaker Identity in Prompt-Based Text-to-Speech using Natural Language Descriptions | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://reppy4620.github.io/demo.promptttspp/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448173-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448173) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08140-b31b1b.svg)](https://arxiv.org/abs/2309.08140) | :heavy_minus_sign: |
| VoiceLDM: Text-to-Speech with Environmental Context | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://voiceldm.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/glory20h/VoiceLDM?style=flat)](https://github.com/glory20h/VoiceLDM) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448268-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448268) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.13664-b31b1b.svg)](https://arxiv.org/abs/2309.13664) | :heavy_minus_sign: |
| DETS: End-to-End Single-Stage Text-to-Speech via Hierarchical Diffusion Gan Models | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446855-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446855) | :heavy_minus_sign: |
| Latent Filling: Latent Space Data Augmentation for Zero-Shot Speech Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://srtts.github.io/latent-filling/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446098-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446098) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.03538-b31b1b.svg)](https://arxiv.org/abs/2310.03538) | :heavy_minus_sign: |
| An Experimental Comparison of Noise-Robust Text-to-Speech Synthesis Systems based On Self-Supervised Representation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446750-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446750) | :heavy_minus_sign: |
| Mels-TTS: Multi-Emotion Multi-Lingual Multi-Speaker Text-to-Speech System via Disentangled Style Tokens | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446852-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446852) | :heavy_minus_sign: |
| Energy-based Models for Speech Synthesis | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447218-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447218) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.12765-b31b1b.svg)](https://arxiv.org/abs/2310.12765) | :heavy_minus_sign: |
| Improving Language Model-based Zero-Shot Text-to-Speech Synthesis with Multi-Scale Acoustic Prompts | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://thuhcsi.github.io/icassp2024-msvalle/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447815-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447815) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.11977-b31b1b.svg)](https://arxiv.org/abs/2309.11977) | :heavy_minus_sign: |
| Minimally-Supervised Speech Synthesis with Conditional Diffusion Model and Language Model: A Comparative Study of Semantic Coding | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://qiangchunyu.github.io/Diff-LM-Speech/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446203-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446203) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2307.15484-b31b1b.svg)](https://arxiv.org/abs/2307.15484) | :heavy_minus_sign: |
| High-Fidelity Speech Synthesis with Minimal Supervision: All using Diffusion Models | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://qiangchunyu.github.io/Diff-Speech/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448495-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448495) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.15512-b31b1b.svg)](https://arxiv.org/abs/2309.15512) | :heavy_minus_sign: |
| Reflow-TTS: A Rectified Flow Model for High-Fidelity Text-to-Speech | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://gwh22.github.io/ReFlow-TTS/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447822-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447822) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.17056-b31b1b.svg)](https://arxiv.org/abs/2309.17056) | :heavy_minus_sign: |
| Adversarial Learning on Compressed Posterior Space for Non-Iterative Score-based End-to-End Text-to-Speech | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446958-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446958) | :heavy_minus_sign: |
| DCTTS: Discrete Diffusion Model with Contrastive Learning for Text-to-Speech Generation | [![GitHub](https://img.shields.io/github/stars/lawtherWu/DCTTS?style=flat)](https://github.com/lawtherWu/DCTTS) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447661-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447661) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.06787-b31b1b.svg)](https://arxiv.org/abs/2309.06787) | :heavy_minus_sign: |
| Enhancing Multilingual TTS with Voice Conversion based Data Augmentation and Posterior Embedding | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448471-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448471) | :heavy_minus_sign: |
| Ultra-Lightweight Neural Differential DSP Vocoder for High Quality Speech Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ddsp-vocoder.github.io/ddsp/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447948-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447948) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.10460-b31b1b.svg)](https://arxiv.org/abs/2401.10460) | :heavy_minus_sign: |
| Fregrad: Lightweight and Fast Frequency-Aware Diffusion Vocoder | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://mm.kaist.ac.kr/projects/FreGrad) <br /> [![GitHub](https://img.shields.io/github/stars/kaistmm/fregrad?style=flat)](https://github.com/kaistmm/fregrad) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447251-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447251) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.10032-b31b1b.svg)](https://arxiv.org/abs/2401.10032) | :heavy_minus_sign: |
| BIGVSAN: Enhancing Gan-based Neural Vocoders with Slicing Adversarial Network | [![GitHub](https://img.shields.io/github/stars/sony/bigvsan?style=flat)](https://github.com/sony/bigvsan) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446121-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446121) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.02836-b31b1b.svg)](https://arxiv.org/abs/2309.02836) | :heavy_minus_sign: |
| Noise-Robust Zero-Shot Text-to-Speech Synthesis Conditioned on Self-Supervised Speech-Representation Model with Adapters | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://ntt-hilab-gensp.github.io/icassp2024robustTTS/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447809-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447809) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.05111-b31b1b.svg)](https://arxiv.org/abs/2401.05111) | :heavy_minus_sign: |
| Speak While You Think: Streaming Speech Synthesis During Text Generation | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://s3.us-south.objectstorage.softlayer.net/zk-wav-data/Webpages/LLM2Speech_ICASSP2024/index.html) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446214-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446214) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.11210-b31b1b.svg)](https://arxiv.org/abs/2309.11210) | :heavy_minus_sign: |
| StoryTTS: A Highly Expressive Text-to-Speech Dataset with Rich Textual Expressiveness Annotations | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://goarsenal.github.io/StoryTTS/) <br /> [![GitHub](https://img.shields.io/github/stars/X-LANCE/StoryTTS?style=flat)](https://github.com/X-LANCE/StoryTTS) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446023-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446023) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2404.14946-b31b1b.svg)](https://arxiv.org/abs/2404.14946) | :heavy_minus_sign: |
| GLA-GRAD: A Griffin-Lim Extended Waveform Generation Diffusion Model | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://gla-grad.github.io/) <br /> [![GitHub](https://img.shields.io/github/stars/GLA-Grad/GLA-Grad?style=flat)](https://github.com/GLA-Grad/GLA-Grad) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446058-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446058) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2402.15516-b31b1b.svg)](https://arxiv.org/abs/2402.15516) | :heavy_minus_sign: |
| Training Generative Adversarial Network-based Vocoder with Limited Data using Augmentation-Conditional Discriminator | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://www.kecl.ntt.co.jp/people/kaneko.takuhiro/projects/augcondd/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445914-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445914) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2403.16464-b31b1b.svg)](https://arxiv.org/abs/2403.16464) | :heavy_minus_sign: |
| PeriodGrad: Towards Pitch-Controllable Neural Vocoder based on a Diffusion Probabilistic Model | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448502-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448502) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2402.14692-b31b1b.svg)](https://arxiv.org/abs/2402.14692) | :heavy_minus_sign: |
| ED-TTS: Multi-Scale Emotion Modeling using Cross-Domain Emotion Diarization for Emotional Speech Synthesis | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446467-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446467) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2401.08166-b31b1b.svg)](https://arxiv.org/abs/2401.08166) | :heavy_minus_sign: |
| Considering Temporal Connection between Turns for Conversational Speech Synthesis | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448356-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448356) | :heavy_minus_sign: |
| Hierarchical Emotion Prediction and Control in Text-to-Speech Synthesis | [![GitHub](https://img.shields.io/github/stars/shinshoji01/Text-Hierarchical-ED?style=flat)](https://github.com/shinshoji01/Text-Hierarchical-ED) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445996-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445996) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2405.09171-b31b1b.svg)](https://arxiv.org/abs/2405.09171) | :heavy_minus_sign: |
| Controllable Speaking Styles using a Large Language Model | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448400-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448400) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.10321-b31b1b.svg)](https://arxiv.org/abs/2305.10321) | :heavy_minus_sign: |
| Concss: Contrastive-based Context Comprehension for Dialogue-Appropriate Prosody in Conversational Speech Synthesis | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446506-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446506) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.10358-b31b1b.svg)](https://arxiv.org/abs/2312.10358) | :heavy_minus_sign: |
| SponTTS: Modeling and Transferring Spontaneous Style for TTS | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://kkksuper.github.io/SponTTS/) <br /> [![GitHub](https://img.shields.io/github/stars/kkksuper/SponTTS?style=flat)](https://github.com/kkksuper/SponTTS) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10445828-E4A42C.svg)](https://ieeexplore.ieee.org/document/10445828) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2311.07179-b31b1b.svg)](https://arxiv.org/abs/2311.07179) | :heavy_minus_sign: |
| Controllable Prosody Generation with Partial Inputs | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446859-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446859) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2303.09446-b31b1b.svg)](https://arxiv.org/abs/2303.09446) | :heavy_minus_sign: |
| StyleSpeech: Self-Supervised Style Enhancing with VQ-VAE-based Pre-Training for Expressive Audiobook Speech Synthesis | [![GitHub Page](https://img.shields.io/badge/GitHub-Page-159957.svg)](https://chenxuey20.github.io/StyleSpeech/) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446352-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446352) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2312.12181-b31b1b.svg)](https://arxiv.org/abs/2312.12181) | :heavy_minus_sign: |
| TNFormer: Single-Pass Multilingual Text Normalization with a Transformer Decoder Model | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446848-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446848) | :heavy_minus_sign: |
| A Unified Front-End Framework for English Text-to-Speech Synthesis | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10447144-E4A42C.svg)](https://ieeexplore.ieee.org/document/10447144) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2305.10666-b31b1b.svg)](https://arxiv.org/abs/2305.10666) | :heavy_minus_sign: |
| Collaborative Watermarking for Adversarial Speech Synthesis | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448134-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448134) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.15224-b31b1b.svg)](https://arxiv.org/abs/2309.15224) | :heavy_minus_sign: |
| Mapache: Masked Parallel Transformer for Advanced Speech Editing and Synthesis | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448121-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448121) | :heavy_minus_sign: |
| Diversity-based Core-Set Selection for Text-to-Speech with Linguistic and Acoustic Features | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448068-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448068) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.08127-b31b1b.svg)](https://arxiv.org/abs/2309.08127) | :heavy_minus_sign: |
| Fewer-Token Neural Speech Codec with Time-Invariant Codes | [![GitHub](https://img.shields.io/github/stars/y-ren16/TiCodec?style=flat)](https://github.com/y-ren16/TiCodec) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448454-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448454) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2310.00014-b31b1b.svg)](https://arxiv.org/abs/2310.00014) | :heavy_minus_sign: |
| Convnext-TTS and Convnext-VC: Convnext-based Fast End-to-End Sequence-to-Sequence Text-to-Speech and Voice Conversion | [![WEB Page](https://img.shields.io/badge/WEB-Page-159957.svg)](https://ast-astrec.nict.go.jp/demo_samples/convnext-tts_vc/index.html) | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446890-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446890) | :heavy_minus_sign: |
| SYNTHE-SEES: Face based Text-to-Speech for Virtual Speaker | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10448433-E4A42C.svg)](https://ieeexplore.ieee.org/document/10448433) | :heavy_minus_sign: |
| Language-Oriented Communication with Semantic Coding and Knowledge Distillation for Text-to-Image Generation | :heavy_minus_sign: | [![IEEE Xplore](https://img.shields.io/badge/IEEE-10446638-E4A42C.svg)](https://ieeexplore.ieee.org/document/10446638) <br /> [![arXiv](https://img.shields.io/badge/arXiv-2309.11127-b31b1b.svg)](https://arxiv.org/abs/2309.11127) | :heavy_minus_sign: |
