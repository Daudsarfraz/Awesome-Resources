# Nature language process

- Aspect Specific Opinion Expression Extraction using Attention based LSTM-CRF Network. [`arxiv`](https://arxiv.org/abs/1902.02709)
- BERT and PALs: Projected Attention Layers for Efficient Adaptation in Multi-Task Learning. [`arxiv`](https://arxiv.org/abs/1902.02671)
- BioBERT: pre-trained biomedical language representation model for biomedical text mining. [`arxiv`](https://arxiv.org/abs/1901.08746)
- Cross-lingual Language Model Pretraining. [`arxiv`](https://arxiv.org/abs/1901.07291)
- Does BERT Make Any Sense? Interpretable Word Sense Disambiguation with Contextualized Embeddings. [`arxiv`](https://arxiv.org/abs/1909.10430) [`code`](https://github.com/uhh-lt/bert-sense)
- GILT: Generating Images from Long Text. [`arxiv`](https://arxiv.org/abs/1901.02404)
- Open Research Knowledge Graph: Towards Machine Actionability in Scholarly Communication. [`arxiv`](https://arxiv.org/abs/1901.10816)
- SumQE: a BERT-based Summary Quality Estimation Model. [`arxiv`](https://arxiv.org/abs/1909.00578) [`code`](https://github.com/nlpaueb/SumQE)
- Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context. [`arxiv`](https://arxiv.org/abs/1901.02860) [`code`](https://github.com/kimiyoung/transformer-xl)

## Embedding

- A Multi-Resolution Word Embedding for Document Retrieval from Large Unstructured Knowledge Bases. [`arxiv`](https://arxiv.org/abs/1902.00663)
- Word Embeddings for Sentiment Analysis: A Comprehensive Empirical Survey. [`arxiv`](https://arxiv.org/abs/1902.00753)
- Fast Transformer Decoding: One Write-Head is All You Need. [`arxiv`](https://arxiv.org/abs/1911.02150)

## NMT

- Modeling Latent Sentence Structure in Neural Machine Translation. [`arxiv`](https://arxiv.org/abs/1901.06436)
- Training on Synthetic Noise Improves Robustness to Natural Noise in Machine Translation. [`arxiv`](https://arxiv.org/abs/1902.01509)

## Reading Comprehension

- DREAM: A Challenge Dataset and Models for Dialogue-Based Reading Comprehension. [`arxiv`](https://arxiv.org/abs/1902.00164)
- Review Conversational Reading Comprehension. [`arxiv`](https://arxiv.org/abs/1902.00821)


## Recommender Systems

- Behavior Sequence Transformer for E-commerce Recommendation in Alibaba. [`arxiv`](https://arxiv.org/pdf/1905.06874.pdf)

## Text Classification

- Delta-training: Simple Semi-Supervised Text Classification using Pretrained Word Embeddings. [`arxiv`](https://arxiv.org/abs/1901.07651)
- EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks. [`arxiv`](https://arxiv.org/abs/1901.11196) [`code`](https://github.com/jasonwei20/eda_nlp)
- Hierarchical Multi-label Text Classification: An Attention-based Recurrent Network Approach. [`pdf`](https://dl.acm.org/doi/pdf/10.1145/3357384.3357885?download=true) [`code`](https://github.com/RandolphVI/Hierarchical-Multi-Label-Text-Classification)