## A variety of attention papers

tl;dr: attention seems to work better for language tasks (NMT, summarization, conversation, question answering) than visual tasks. Below is an impressively diverse variety of architectures for arranging attentional vectors - they can be soft or hard; if hard, they can be local or not; attention can be layered; attention can be collected into matrices; attention history can be tracked via RNN.

* 24 Jun 2014, 417 citations: [Recurrent Models of Visual Attention](https://arxiv.org/abs/1406.6247): an early visual "attention" paper; trains an RNN to take as input a glimpse and produce as output a new glimpse, uses RL to train as it's nondifferentiable.
* 17 Aug 2015, 417 citations: [Effective Approaches to Attention-based Neural Machine Translation](https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/effective-approaches-nmt-attention.md): the decoder, when deciding what word to generate, only attends over a local window of source words (tuneable via hyperparameter).
* 2 Sep 2015, 269 citations: [A Neural Attention Model for Abstractive Sentence Summarization](https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/neural-attention-model-for-abstractive-sentence-summarization.md): using local attention to generate abstractive sentence summaries.
* 29 Oct 2015, 35 citations: [Attention with Intention for a Neural Network Conversation Model](https://arxiv.org/abs/1510.08565): not really about attention, actually - key addition to conversation modeling is a third RNN that represents the arc of the conversation (the "intention").
* 6 Jan 2016, 56 citations: [Multi-Way, Multilingual Neural Machine Translation with a Shared Attention Mechanism](https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/multi-way-nmt-shared-attention.md): a single model trained to translate between many language pairs, where the attention mechanism (the weights?) are reused for different language pairs. Doesn't appear to create an intermediate representation, as the authors were probably attempting to do.
* 15 Jul 2016, 36 citations: [Attention-over-Attention Neural Networks for Reading Comprehension](https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/att-over-att.md): computes two different attentional vectors and multiplies them together for machine comprehension tasks (answer a fill-in-the-blank question about a document)
* 18 Jul 2016, 9 citations: [Neural Machine Translation with Recurrent Attention Modeling](https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/nmt-rec-attention.md): it's probably helpful to look at the history of attention when figure out where to attend to next, so wrap the attention mechanism in an RNN.
* 9 Mar 2017, 10 citations: [A Structured Self-attentive Sentence Embedding](https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/self_attention_embedding.md): create 2D sentence embeddings, where rows are attentional vectors for each RNN time step, and use a penalization term to encourage them to be different.
* 12 Jun 2017, 12 citations: [Attention Is All You Need](https://github.com/JasonBenn/deep-learning-paper-notes/blob/master/notes/attention-is-all-you-need.md): by dispensing with the RNN and CNN parts of NMT and building progressively more complex representations using only word vectors and attention, Google achieved an order of magnitude better performance than existing models and a dramatic improvement on BLEU scores.

#### Words I don't know

* Abstractive sentence summarization: as opposed to "extractive", in which parts of the source are cropped out and the remains are stitched together; "abstractive" attempts to rephrase the source, even if that involves language that didn't appear in the original.
* Beam search decoder: "beam search" is a way of searching through graphs breadth-first, but each level is sorted according to a promisingness heuristic and truncated after the beam's width (a hyperparameter). It's like tree pruning for graphs.
* "soft alignment" attention mechanism: compute at least _some_ attention for all possible items, even if it's near zero (like how softmax computes a probability for every class in classification). Odd that it's called "alignment", because for soft attention, no "alignment" would be necessary.
* seq2seq: useful for NMT, text summarization, conversational modeling, image captioning
